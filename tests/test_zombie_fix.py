#!/usr/bin/env python3
# coding=utf-8
"""
æµ‹è¯•MPMS zombieè¿›ç¨‹ä¿®å¤
"""

import pytest
import time
import os
import multiprocessing
import threading
import sys

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from mpms import MPMS


class TestZombieFix:
    """æµ‹è¯•zombieè¿›ç¨‹ä¿®å¤"""
    
    def test_process_crash_recovery(self):
        """æµ‹è¯•è¿›ç¨‹å´©æºƒåçš„æ¢å¤å’Œzombieæ¸…ç†"""
        results = []
        
        def crash_worker(task_id):
            """ä¼šå´©æºƒçš„worker"""
            if task_id == 0:
                # ç¬¬ä¸€ä¸ªä»»åŠ¡å¯¼è‡´è¿›ç¨‹å´©æºƒ
                os._exit(1)
            time.sleep(0.1)
            return f"Task {task_id} done"
        
        def collector(meta, result):
            results.append(result)
        
        # åˆ›å»ºMPMSå®ä¾‹
        m = MPMS(
            worker=crash_worker,
            collector=collector,
            processes=2,
            threads=1,
            subproc_check_interval=1,  # 1ç§’æ£€æŸ¥ä¸€æ¬¡
        )
        
        m.start()
        
        # æäº¤ä¼šå¯¼è‡´å´©æºƒçš„ä»»åŠ¡
        m.put(0)
        
        # æäº¤æ­£å¸¸ä»»åŠ¡
        for i in range(1, 5):
            m.put(i)
        
        # ç­‰å¾…ä»»åŠ¡å¤„ç†å’Œè¿›ç¨‹æ¢å¤
        time.sleep(5)  # å¢åŠ ç­‰å¾…æ—¶é—´
        
        # æ‰‹åŠ¨è§¦å‘æ£€æŸ¥ç¡®ä¿è¿›ç¨‹æ¢å¤
        m._subproc_check()
        time.sleep(1)
        
        # æ£€æŸ¥è¿›ç¨‹æ± çŠ¶æ€
        alive_count = sum(1 for p in m.worker_processes_pool.values() if p.is_alive())
        assert alive_count >= 1, f"Expected at least 1 alive process, got {alive_count}"
        
        # å…³é—­å¹¶ç­‰å¾…
        m.close()
        m.join()
        
        # éªŒè¯æ­£å¸¸ä»»åŠ¡éƒ½å®Œæˆäº†
        assert len(results) >= 4, f"Expected at least 4 results, got {len(results)}"
    
    def test_join_called_on_dead_process(self):
        """æµ‹è¯•æ­»äº¡è¿›ç¨‹æ˜¯å¦è°ƒç”¨äº†join"""
        join_called = threading.Event()
        original_join = multiprocessing.Process.join
        
        def mock_join(self, timeout=None):
            """Mock joinæ–¹æ³•"""
            if not self.is_alive():
                join_called.set()
            return original_join(self, timeout)
        
        # ä¸´æ—¶æ›¿æ¢joinæ–¹æ³•
        multiprocessing.Process.join = mock_join
        
        try:
            def crash_worker(x):
                os._exit(1)
            
            m = MPMS(
                worker=crash_worker,
                processes=1,
                threads=1,
                subproc_check_interval=0.5,
            )
            
            m.start()
            m.put(1)
            
            # ç­‰å¾…è¿›ç¨‹å´©æºƒå’Œæ£€æŸ¥
            time.sleep(2)
            
            # éªŒè¯joinè¢«è°ƒç”¨äº†
            assert join_called.is_set(), "join() was not called on dead process"
            
            m.close()
            m.join()
            
        finally:
            # æ¢å¤åŸå§‹æ–¹æ³•
            multiprocessing.Process.join = original_join
    
    def test_process_restart_maintains_count(self):
        """æµ‹è¯•è¿›ç¨‹é‡å¯åç»´æŒé…ç½®çš„è¿›ç¨‹æ•°"""
        def sometimes_crash_worker(task_id):
            if task_id % 10 == 0:
                os._exit(1)
            time.sleep(0.05)
            return task_id
        
        m = MPMS(
            worker=sometimes_crash_worker,
            processes=4,
            threads=2,
            subproc_check_interval=1,
        )
        
        m.start()
        
        # åˆå§‹æ£€æŸ¥
        assert len(m.worker_processes_pool) == 4
        
        # æäº¤ä¸€äº›ä¼šå¯¼è‡´å´©æºƒçš„ä»»åŠ¡
        for i in range(30):
            m.put(i)
        
        # ç­‰å¾…ä¸€äº›è¿›ç¨‹å´©æºƒå’Œæ¢å¤
        time.sleep(3)
        
        # æ£€æŸ¥è¿›ç¨‹æ•°æ˜¯å¦ç»´æŒ
        assert len(m.worker_processes_pool) == 4, f"Expected 4 processes, got {len(m.worker_processes_pool)}"
        
        # æ£€æŸ¥æ‰€æœ‰è¿›ç¨‹éƒ½æ˜¯æ´»çš„
        alive_count = sum(1 for p in m.worker_processes_pool.values() if p.is_alive())
        assert alive_count == 4, f"Expected 4 alive processes, got {alive_count}"
        
        m.close()
        m.join()
    
    def test_graceful_shutdown(self):
        """æµ‹è¯•ä¼˜é›…å…³é—­åŠŸèƒ½"""
        task_count = 0
        
        def slow_worker(x):
            nonlocal task_count
            time.sleep(0.1)
            task_count += 1
            return x
        
        m = MPMS(
            worker=slow_worker,
            processes=2,
            threads=2,
        )
        
        m.start()
        
        # æäº¤ä»»åŠ¡
        for i in range(20):
            m.put(i)
        
        # ä¼˜é›…å…³é—­
        start_time = time.time()
        success = m.graceful_shutdown(timeout=5.0)
        elapsed = time.time() - start_time
        
        assert success, "Graceful shutdown failed"
        assert elapsed < 5.0, f"Graceful shutdown took too long: {elapsed}s"
        assert task_count == 20, f"Not all tasks completed: {task_count}/20"
        
        # éªŒè¯æ‰€æœ‰è¿›ç¨‹éƒ½è¢«æ¸…ç†äº†
        assert len(m.worker_processes_pool) == 0
    
    def test_collector_handles_timeout_tasks(self):
        """æµ‹è¯•collectoræ­£ç¡®å¤„ç†è¶…æ—¶ä»»åŠ¡"""
        results = []
        errors = []
        
        def hang_worker(x):
            if x == 0:
                time.sleep(10)  # ä¼šè¶…æ—¶çš„ä»»åŠ¡
            return x
        
        def collector(meta, result):
            if isinstance(result, Exception):
                errors.append(result)
            else:
                results.append(result)
        
        m = MPMS(
            worker=hang_worker,
            collector=collector,
            processes=1,
            threads=1,
            lifecycle_duration_hard=1,  # 1ç§’è¶…æ—¶
        )
        
        m.start()
        
        # æäº¤ä¼šè¶…æ—¶çš„ä»»åŠ¡
        m.put(0)
        # æäº¤æ­£å¸¸ä»»åŠ¡
        m.put(1)
        
        # ç­‰å¾…è¶…æ—¶
        time.sleep(2)
        
        # æ‰‹åŠ¨è§¦å‘æ£€æŸ¥
        m._subproc_check()
        
        # ç­‰å¾…collectorå¤„ç†
        time.sleep(0.5)
        
        # éªŒè¯è¶…æ—¶ä»»åŠ¡è¢«æ­£ç¡®å¤„ç†
        assert len(errors) >= 1, "Timeout error not reported"
        assert any(isinstance(e, TimeoutError) for e in errors), "No TimeoutError found"
        
        m.close()
        m.join()
    
    def test_close_wait_for_empty(self):
        """æµ‹è¯•wait_for_emptyå‚æ•°"""
        processed = []
        
        def worker(x):
            time.sleep(0.1)
            processed.append(x)
            return x
        
        m = MPMS(worker=worker, processes=2, threads=2)
        m.start()
        
        # æäº¤ä»»åŠ¡
        for i in range(10):
            m.put(i)
        
        # ç«‹å³å…³é—­ï¼Œç­‰å¾…é˜Ÿåˆ—æ¸…ç©º
        start_time = time.time()
        m.close(wait_for_empty=True)
        elapsed = time.time() - start_time
        
        # éªŒè¯ç­‰å¾…äº†ä¸€æ®µæ—¶é—´
        assert elapsed >= 0.1, f"Did not wait for queue to empty: {elapsed}s"
        
        m.join()
        
        # éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½è¢«å¤„ç†äº†
        assert len(processed) == 10, f"Not all tasks processed: {len(processed)}/10"


if __name__ == "__main__":
    """ç›´æ¥è¿è¡Œæµ‹è¯•"""
    test = TestZombieFix()
    
    print("è¿è¡Œæµ‹è¯•: test_process_crash_recovery")
    test.test_process_crash_recovery()
    print("âœ… é€šè¿‡")
    
    print("\nè¿è¡Œæµ‹è¯•: test_join_called_on_dead_process")
    test.test_join_called_on_dead_process()
    print("âœ… é€šè¿‡")
    
    print("\nè¿è¡Œæµ‹è¯•: test_process_restart_maintains_count")
    test.test_process_restart_maintains_count()
    print("âœ… é€šè¿‡")
    
    print("\nè¿è¡Œæµ‹è¯•: test_graceful_shutdown")
    test.test_graceful_shutdown()
    print("âœ… é€šè¿‡")
    
    print("\nè¿è¡Œæµ‹è¯•: test_collector_handles_timeout_tasks")
    test.test_collector_handles_timeout_tasks()
    print("âœ… é€šè¿‡")
    
    print("\nè¿è¡Œæµ‹è¯•: test_close_wait_for_empty")
    test.test_close_wait_for_empty()
    print("âœ… é€šè¿‡")
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼") 